{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90f495c8-03d0-4afe-925e-a21e24745d70",
   "metadata": {},
   "source": [
    "# 4.3.\tViolações dos padrões de qualidade do ar no Brasil "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7141dc83-bc60-4d35-9747-e677ea12efaf",
   "metadata": {},
   "source": [
    "Tabela 10 – Ranqueamento das cinco estações com o maior número de violações dos Padrões de Qualidade do Ar de O 3, MP10, MP2,5 e SO2 no ano de 2023. \n",
    "    TENTAR FAZER UMA TABELA ITERATIVA ONDE O USUÁRIO POSSA FILTRAR AS ESTAÇÕES\n",
    "\n",
    "    TENTAR FAZER UM DROPDOWN MENU PARA ESCOLHER QUAL SÉRIE TEMPORAL VISUALIZAR NO LIVRO. Colocar padrões da CONAMA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea6ac09c-0802-4cbb-b28f-1998b93b9abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68b2e4e9e2a4a0db419cb46027067d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(DatePicker(value=datetime.date(2025, 1, 1), description='Start:', step=1), DatePicker(value=dat…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbd6d80fce03449caaff397383249585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4954d90ce2147c6abfe1970d12b10ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd1c945bcb24d2c9fe3d4fb95d6e245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Download CSV', disabled=True, style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ecc346a40ab43a1b561823e0421fe5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "from itables import show\n",
    "import itables.options as opt\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Setup itables\n",
    "opt.lengthMenu = [10, 25, 50, 100]\n",
    "opt.scrollX = True\n",
    "opt.columnDefs = [{\"className\": \"dt-center\", \"targets\": \"_all\"}]\n",
    "\n",
    "# Sample Data\n",
    "df = pd.read_csv('https://lcqar.ufsc.br/files/RS0009_MP10.csv')\n",
    "\n",
    "# Widgets\n",
    "start_date = widgets.DatePicker(description='Start:', value=pd.to_datetime(\"2025-01-01\").date())\n",
    "end_date = widgets.DatePicker(description='End:', value=pd.to_datetime(\"2025-04-01\").date())\n",
    "\n",
    "filter_button = widgets.Button(description=\"Filter\", button_style='primary')\n",
    "csv_button = widgets.Button(description=\"Download CSV\", button_style='success', disabled=True)\n",
    "\n",
    "output_table = widgets.Output()\n",
    "output_download = widgets.Output()\n",
    "output_plot = widgets.Output()\n",
    "\n",
    "\n",
    "\n",
    "def tratar_dados(df):\n",
    "    df['datetime'] = pd.to_datetime({\n",
    "      'year': df['ANO'],\n",
    "      'month': df['MES'],\n",
    "      'day': df['DIA'],\n",
    "      'hour': pd.to_datetime(df['HORA'], format='%H:%M:%S').dt.hour\n",
    "    })\n",
    "    # Substitui , por . \n",
    "    df['VALOR'] = df['VALOR'].replace(',', '.', regex=True).copy()\n",
    "    # Converte para float, forçando erro para NaN\n",
    "    df['VALOR'] = pd.to_numeric(df['VALOR'], errors='coerce').copy()\n",
    "    # Transforma valores negativos em NaN\n",
    "    df.loc[df['VALOR'] < 0, 'VALOR'] = np.nan\n",
    "    time_range = pd.date_range(df['datetime'].min(), df['datetime'].max(), freq='h').to_series(name='datetime')\n",
    "    df = pd.merge(time_range, df,how='left')\n",
    "    #df = df.set_index('datetime', drop=False)\n",
    "    df['datetime'] = pd.to_datetime(df['datetime']).copy()\n",
    "    return df\n",
    "    \n",
    "df = tratar_dados(df)\n",
    "filtered_df = df.copy()\n",
    "\n",
    "def split_nan_segments(x, y):\n",
    "    \"\"\"Splits x and y into segments where y is not NaN\"\"\"\n",
    "    segments = []\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    isnan = np.isnan(y)\n",
    "    start = 0\n",
    "    for i in range(1, len(y)):\n",
    "        if isnan[i] and not isnan[i-1]:\n",
    "            segments.append((x[start:i], y[start:i]))\n",
    "            start = i + 1\n",
    "        elif not isnan[i] and isnan[i-1]:\n",
    "            start = i\n",
    "    if not isnan[-1]:\n",
    "        segments.append((x[start:], y[start:]))\n",
    "    return segments\n",
    "def iterative_raw_timeseries(df):\n",
    "    df = tratar_dados(df)\n",
    "    dates = df['datetime']\n",
    "    # Create the figure\n",
    "    #fig = go.Figure()\n",
    "    fig = make_subplots(rows=1, cols=1) \n",
    "    # raw\n",
    "    segments = split_nan_segments(df['datetime'], df.VALOR)\n",
    "    for seg_x, seg_y in segments:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=seg_x,\n",
    "            y=seg_y,\n",
    "            #fill='tozeroy',\n",
    "            line=dict(color='rgba(153, 153, 255, 1)', width=1),\n",
    "            #fillcolor='rgba(255,255,255,1)',\n",
    "            #fillcolor='rgba(153, 153, 255,0.1)',\n",
    "            showlegend=False,\n",
    "            name='Série temporal',\n",
    "            mode='lines',\n",
    "            connectgaps=False\n",
    "        ))\n",
    "    # Update layout for better presentation\n",
    "    fig.update_layout(\n",
    "        title='Série temporal',\n",
    "        hovermode='x unified', # Shows hover info for all traces at a given x-coordinate\n",
    "        height=600, width=800,\n",
    "        plot_bgcolor='rgba(0.9,0.9,0.9,0.2)')\n",
    "    unidade = '(ug/m³)'\n",
    "    fig.update_yaxes(title_text=\"Concentração<br>Série completa\"+unidade, row=5, col=1)\n",
    "    fig.update_xaxes(title_text=\"Dia/Mês/Ano Hora\")\n",
    "    return fig\n",
    "\n",
    "# Filter function\n",
    "def on_filter_clicked(_):\n",
    "    global filtered_df\n",
    "    with output_table:\n",
    "        clear_output()\n",
    "        mask = (df['datetime'].dt.date >= start_date.value) & (df['datetime'].dt.date <= end_date.value)\n",
    "        filtered_df = df.loc[mask]\n",
    "        show(filtered_df)\n",
    "    \n",
    "    with output_plot:\n",
    "        clear_output()\n",
    "        if not filtered_df.empty:\n",
    "            #fig, ax = plt.subplots(figsize=(8, 3))\n",
    "            fig = iterative_raw_timeseries(df)\n",
    "            #ax.plot(filtered_df['datetime'], filtered_df['VALOR'], marker='o')\n",
    "            #ax.set_title(\"Filtered Series\")\n",
    "            #ax.set_xlabel(\"Date\")\n",
    "            #ax.set_ylabel(\"Value\")\n",
    "            #ax.grid(True)\n",
    "            #plt.xticks(rotation=45)\n",
    "            #plt.tight_layout()\n",
    "            display(fig)\n",
    "    \n",
    "    csv_button.disabled = filtered_df.empty\n",
    "\n",
    "# CSV download function\n",
    "def on_csv_clicked(_):\n",
    "    with output_download:\n",
    "        clear_output()\n",
    "        csv_buffer = BytesIO()\n",
    "        filtered_df.to_csv(csv_buffer, index=False)\n",
    "        b64 = base64.b64encode(csv_buffer.getvalue()).decode()\n",
    "        filename = \"filtered_data.csv\"\n",
    "        payload = f\"data:text/csv;base64,{b64}\"\n",
    "        html = f\"\"\"\n",
    "        <html>\n",
    "        <body>\n",
    "        <a id=\"download_link\" download=\"{filename}\" href=\"{payload}\"></a>\n",
    "        <script>document.getElementById('download_link').click();</script>\n",
    "        </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "        display(HTML(html))\n",
    "\n",
    "# Bind buttons\n",
    "filter_button.on_click(on_filter_clicked)\n",
    "csv_button.on_click(on_csv_clicked)\n",
    "\n",
    "# Layout\n",
    "ui = widgets.HBox([start_date, end_date, filter_button])\n",
    "display(ui, output_table, output_plot, csv_button, output_download)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d51292d-2c99-4bd8-b0a5-c4375c752fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63cb543155f40f4bc93396923fe191c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Station:', options=('BA0007RA004',), value='BA0007RA004'), Dropdown(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf547c169dfa431eaf1af0752f67f1a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(DatePicker(value=None, description='Start date:', step=1), DatePicker(value=None, description='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29704987aa8f487b9a4060c118830220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d86410bc5e466d9d791bd067a6d1f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eeceb06a7f2484bab4e9c36c05eb9be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6fd67b192bf4aea8f5c1cad1ee384c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='success', description='Download Filtered CSV', disabled=True, style=Button…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd41fcfff8f243c09105d94dd201a934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "from itables import show\n",
    "import itables.options as opt\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Configure itables\n",
    "opt.lengthMenu = [10, 25, 50, 100]\n",
    "opt.scrollX = True\n",
    "\n",
    "# Settings\n",
    "DATA_FOLDER = 'https://lcqar.ufsc.br/files/2023'  # adjust as needed\n",
    "\n",
    "# Caminho para a pasta de dados\n",
    "rootPath = os.path.dirname(os.getcwd())\n",
    "\n",
    "# Lendo o csv\n",
    "aqmData = pd.read_csv(rootPath+'/data/Monitoramento_QAr_BR_teste.csv',encoding = 'unicode_escape')\n",
    "\n",
    "# Create dict: station -> list of pollutants\n",
    "station_pollutants = aqmData.groupby(\"ID_MMA\")[\"POLUENTE\"].unique().apply(list).to_dict()\n",
    "# Set station list\n",
    "AVAILABLE_STATIONS = sorted(station_pollutants.keys())\n",
    "\n",
    "# Widgets\n",
    "station_dropdown = widgets.Dropdown(options=AVAILABLE_STATIONS, description='Station:')\n",
    "pollutant_dropdown = widgets.Dropdown(description='Pollutant:')\n",
    "load_button = widgets.Button(description=\"Load CSV\", button_style='primary')\n",
    "start_date = widgets.DatePicker(description='Start date:')\n",
    "end_date = widgets.DatePicker(description='End date:')\n",
    "filter_button = widgets.Button(description=\"Apply Filter\", button_style='info', disabled=True)\n",
    "csv_button = widgets.Button(description=\"Download Filtered CSV\", button_style='success', disabled=True)\n",
    "\n",
    "# Output widgets\n",
    "output_error = widgets.Output()\n",
    "output_table = widgets.Output()\n",
    "output_plot = widgets.Output()\n",
    "output_download = widgets.Output()\n",
    "\n",
    "# DataFrames\n",
    "loaded_df = pd.DataFrame()\n",
    "filtered_df = pd.DataFrame()\n",
    "\n",
    "def tratar_dados(df):\n",
    "    # Convert all to string first\n",
    "    hour_str = df['HORA'].astype(str)\n",
    "\n",
    "    # Now parse hours and minutes from string\n",
    "    def parse_hour_minute(val):\n",
    "        if ':' in val:\n",
    "            parts = val.split(':')\n",
    "            return int(parts[0]), int(parts[1])\n",
    "        else:\n",
    "            # If float stored as string, convert to float and extract hour/min\n",
    "            f = float(val)\n",
    "            hour = int(f)\n",
    "            minute = int(round((f - hour) * 60))\n",
    "            return hour, minute\n",
    "\n",
    "    parsed = hour_str.apply(parse_hour_minute)\n",
    "    df['HORA'] = parsed.apply(lambda x: x[0])\n",
    "\n",
    "\n",
    "    df['datetime'] = pd.to_datetime({\n",
    "      'year': df['ANO'],\n",
    "      'month': df['MES'],\n",
    "      'day': df['DIA'],\n",
    "      'hour': df['HORA'],        \n",
    "    }, errors='coerce')\n",
    "    # Substitui , por . \n",
    "    df['VALOR'] = df['VALOR'].replace(',', '.', regex=True).copy()\n",
    "    # Converte para float, forçando erro para NaN\n",
    "    df['VALOR'] = pd.to_numeric(df['VALOR'], errors='coerce').copy()\n",
    "    # Transforma valores negativos em NaN\n",
    "    df.loc[df['VALOR'] < 0, 'VALOR'] = np.nan\n",
    "    print(df)\n",
    "    time_range = pd.date_range(df['datetime'].min(), df['datetime'].max(), freq='h').to_series(name='datetime')\n",
    "    df = pd.merge(time_range, df,how='left')\n",
    "    #df = df.set_index('datetime', drop=False)\n",
    "    df['datetime'] = pd.to_datetime(df['datetime']).copy()\n",
    "    return df\n",
    "    \n",
    "def split_nan_segments(x, y):\n",
    "    \"\"\"Splits x and y into segments where y is not NaN\"\"\"\n",
    "    segments = []\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    isnan = np.isnan(y)\n",
    "    start = 0\n",
    "    for i in range(1, len(y)):\n",
    "        if isnan[i] and not isnan[i-1]:\n",
    "            segments.append((x[start:i], y[start:i]))\n",
    "            start = i + 1\n",
    "        elif not isnan[i] and isnan[i-1]:\n",
    "            start = i\n",
    "    if not isnan[-1]:\n",
    "        segments.append((x[start:], y[start:]))\n",
    "    return segments\n",
    "def iterative_raw_timeseries(df):\n",
    "    df = tratar_dados(df)\n",
    "    dates = df['datetime']\n",
    "    # Create the figure\n",
    "    #fig = go.Figure()\n",
    "    fig = make_subplots(rows=1, cols=1) \n",
    "    # raw\n",
    "    segments = split_nan_segments(df['datetime'], df.VALOR)\n",
    "    for seg_x, seg_y in segments:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=seg_x,\n",
    "            y=seg_y,\n",
    "            #fill='tozeroy',\n",
    "            line=dict(color='rgba(153, 153, 255, 1)', width=1),\n",
    "            #fillcolor='rgba(255,255,255,1)',\n",
    "            #fillcolor='rgba(153, 153, 255,0.1)',\n",
    "            showlegend=False,\n",
    "            name='Série temporal',\n",
    "            mode='lines',\n",
    "            connectgaps=False\n",
    "        ))\n",
    "    # Update layout for better presentation\n",
    "    fig.update_layout(\n",
    "        title='Série temporal',\n",
    "        hovermode='x unified', # Shows hover info for all traces at a given x-coordinate\n",
    "        height=600, width=800,\n",
    "        plot_bgcolor='rgba(0.9,0.9,0.9,0.2)')\n",
    "    unidade = '(ug/m³)'\n",
    "    fig.update_yaxes(title_text=\"Concentração<br>Série completa\"+unidade, row=5, col=1)\n",
    "    fig.update_xaxes(title_text=\"Dia/Mês/Ano Hora\")\n",
    "    return fig\n",
    "\n",
    "def update_pollutants(change):\n",
    "    # Get current station from widget (robust to both observer and manual call)\n",
    "    selected_station = change['new'] if isinstance(change, dict) else station_dropdown.value\n",
    "    \n",
    "    # Get corresponding pollutants\n",
    "    new_pollutants = station_pollutants.get(selected_station, [])\n",
    "    \n",
    "    # Save old value to restore if possible\n",
    "    old_value = pollutant_dropdown.value\n",
    "\n",
    "    # Update options with a *copy* to force change detection\n",
    "    pollutant_dropdown.options = list(new_pollutants)\n",
    "    \n",
    "    # Set default or preserve old value if valid\n",
    "    if old_value in new_pollutants:\n",
    "        pollutant_dropdown.value = old_value\n",
    "    elif new_pollutants:\n",
    "        pollutant_dropdown.value = new_pollutants[0]\n",
    "    else:\n",
    "        pollutant_dropdown.value = None\n",
    "# Function to update UI outputs (table, plot)\n",
    "def update_outputs():\n",
    "    with output_table:\n",
    "        clear_output()\n",
    "        show(filtered_df)\n",
    "    with output_plot:\n",
    "        clear_output()\n",
    "        if not filtered_df.empty and 'datetime' in filtered_df.columns:\n",
    "            fig = iterative_raw_timeseries(filtered_df)\n",
    "            display(fig)\n",
    "    csv_button.disabled = filtered_df.empty\n",
    "\n",
    "# Load button action\n",
    "def on_load_clicked(_):\n",
    "    global loaded_df, filtered_df\n",
    "    with output_error, output_table, output_plot, output_download:\n",
    "        clear_output()\n",
    "        station = station_dropdown.value\n",
    "        pollutant = pollutant_dropdown.value\n",
    "        filename = f\"{station}.csv\"\n",
    "        filepath = os.path.join(DATA_FOLDER+'/'+pollutant+'/', filename)\n",
    "        \n",
    "        loaded_df = pd.read_csv(filepath)\n",
    "        loaded_df = tratar_dados(loaded_df)\n",
    "        \n",
    "        filtered_df[:] = loaded_df.copy()\n",
    "\n",
    "        if not loaded_df.empty and 'datetime' in loaded_df.columns:\n",
    "            start_date.value = loaded_df['datetime'].min().date()\n",
    "            end_date.value = loaded_df['datetime'].max().date()\n",
    "\n",
    "        filter_button.disabled = False\n",
    "        update_outputs()\n",
    "\n",
    "# Date filter action\n",
    "def on_filter_clicked(_):\n",
    "    global filtered_df\n",
    "    if 'datetime' not in loaded_df.columns:\n",
    "        return\n",
    "    mask = (df['datetime'].dt.date >= start_date.value) & (df['datetime'].dt.date <= end_date.value)\n",
    "    filtered_df = df.loc[mask]\n",
    "    update_outputs()\n",
    "\n",
    "# CSV download button\n",
    "def on_csv_clicked(_):\n",
    "    with output_download:\n",
    "        clear_output()\n",
    "        csv_buffer = BytesIO()\n",
    "        filtered_df.to_csv(csv_buffer, index=False)\n",
    "        b64 = base64.b64encode(csv_buffer.getvalue()).decode()\n",
    "        filename = f\"{station_dropdown.value}_{pollutant_dropdown.value}_filtered.csv\"\n",
    "        payload = f\"data:text/csv;base64,{b64}\"\n",
    "        html = f\"\"\"\n",
    "        <a id=\"download_link\" download=\"{filename}\" href=\"{payload}\"></a>\n",
    "        <script>document.getElementById('download_link').click();</script>\n",
    "        \"\"\"\n",
    "        display(HTML(html))\n",
    "\n",
    "# Event bindings\n",
    "load_button.on_click(on_load_clicked)\n",
    "filter_button.on_click(on_filter_clicked)\n",
    "csv_button.on_click(on_csv_clicked)\n",
    "\n",
    "\n",
    "# Layout\n",
    "ui_select = widgets.HBox([station_dropdown, pollutant_dropdown, load_button])\n",
    "ui_dates = widgets.HBox([start_date, end_date, filter_button])\n",
    "ui_download = widgets.HBox([csv_button])\n",
    "\n",
    "station_dropdown.observe(update_pollutants, names='value')\n",
    "update_pollutants({'new': station_dropdown.value})  # Trigger initial update\n",
    "\n",
    "\n",
    "display(ui_select, ui_dates, output_error, output_table, output_plot, ui_download, output_download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da01e3c-9cb0-4b84-a8bd-0a0dbb8c8447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
