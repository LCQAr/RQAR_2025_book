{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d601d6-2a3f-4c35-825a-fb86dd43ff04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "\n",
      "üìÖ Processando 2020-08-01\n",
      "üì• Baixando dados da esta√ß√£o Anjo da Guarda (40532F)\n",
      "‚ö†Ô∏è Pulando poluente status, formato inesperado: <class 'str'>\n",
      "üì• Baixando dados da esta√ß√£o Vila Maranh√£o 240823 (41C87F)\n",
      "‚ö†Ô∏è Pulando poluente status, formato inesperado: <class 'str'>\n",
      "üì• Baixando dados da esta√ß√£o BR135 Pedrinhas OUT 19_01_24 - IN30_01_24 (41C892)\n",
      "‚ö†Ô∏è Pulando poluente status, formato inesperado: <class 'str'>\n",
      "üì• Baixando dados da esta√ß√£o Coqueiro IN 27_03_25 (825150)\n",
      "‚ö†Ô∏è Pulando poluente status, formato inesperado: <class 'str'>\n",
      "üì• Baixando dados da esta√ß√£o Vila Sarney 06_23 (41C8AB)\n",
      "‚ö†Ô∏è Pulando poluente status, formato inesperado: <class 'str'>\n",
      "üì• Baixando dados da esta√ß√£o Santa B√°rbara (41C86B)\n",
      "‚ö†Ô∏è Pulando poluente status, formato inesperado: <class 'str'>\n",
      "\n",
      "üìÖ Processando 2020-08-02\n",
      "üì• Baixando dados da esta√ß√£o Anjo da Guarda (40532F)\n",
      "‚ö†Ô∏è Pulando poluente status, formato inesperado: <class 'str'>\n",
      "üì• Baixando dados da esta√ß√£o Vila Maranh√£o 240823 (41C87F)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------- Importa√ß√£o de pacotes ----------------------------------\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "import os\n",
    "\n",
    "# -------------------------\n",
    "# Configura√ß√µes\n",
    "# -------------------------\n",
    "API_URL = \"https://pydjapi.azurewebsites.net/api/envni/chart/small\"\n",
    "\n",
    "DEVICES = {\n",
    "    \"estacao_5\": {\"cod\":\"40532F\", \"nome\":\"Anjo da Guarda\"},\n",
    "    \"estacao_7\": {\"cod\":\"41C87F\", \"nome\": \"Vila Maranh√£o 240823\"},\n",
    "    \"estacao_17\": {\"cod\": \"41C892\", \"nome\": \"BR135 Pedrinhas OUT 19_01_24 - IN30_01_24\"},\n",
    "    \"estacao_1\": {\"cod\": \"825150\", \"nome\": \"Coqueiro IN 27_03_25\"},\n",
    "    \"estacao_25\": {\"cod\": \"41C8AB\", \"nome\": \"Vila Sarney 06_23\"},\n",
    "    \"estacao_35\": {\"cod\": \"41C86B\", \"nome\": \"Santa B√°rbara\"}\n",
    "}\n",
    "\n",
    "pollutant_name_map = {\n",
    "    \"avg_co\": \"CO\",\n",
    "    \"avg_no2\": \"NO2\",\n",
    "    \"avg_so2\": \"SO2\",\n",
    "    \"avg_pm100\": \"PM1.0\",\n",
    "    \"avg_pm10\": \"PM10\",\n",
    "    \"avg_pm25\": \"PM2.5\",\n",
    "    \"avg_o3\": \"O3\",\n",
    "    \"avg_uv\": \"UV\",\n",
    "    \"avg_co_iqar\": \"CO_IQAR\",\n",
    "    \"avg_no2_iqar\": \"NO2_IQAR\",\n",
    "    \"avg_o3_iqar\": \"O3_IQAR\",\n",
    "    \"avg_uv_iqar\": \"UV_IQAR\",\n",
    "    \"avg_pm25_iqar\": \"PM2.5_IQAR\",\n",
    "    \"avg_pm10_iqar\": \"PM10_IQAR\"\n",
    "}\n",
    "\n",
    "\n",
    "OUTPUT_DIR = \"/home/nobre/Notebooks/RQAR_2025_book/data/MA/output_by_station_pollutant\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# -------------------------\n",
    "# Fun√ß√£o para buscar dados de uma esta√ß√£o por dia\n",
    "# -------------------------\n",
    "def fetch_data_day(device_code, date):\n",
    "    \"\"\"\n",
    "    Faz uma requisi√ß√£o para a esta√ß√£o device_code para todo o dia 'date'.\n",
    "    Retorna dicion√°rio JSON.\n",
    "    \"\"\"\n",
    "    dt_start = f\"{date} 00:00\"\n",
    "    dt_end   = f\"{date} 23:59\"\n",
    "    payload = {\n",
    "        \"dt_start\": dt_start,\n",
    "        \"dt_end\": dt_end,\n",
    "        \"device\": device_code\n",
    "    }\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(API_URL, json=payload, headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error fetching {device_code} for {date}: {e}\")\n",
    "        return None\n",
    "\n",
    "# -------------------------\n",
    "# Loop por datas (ex: m√™s de agosto 2025)\n",
    "# -------------------------\n",
    "for YEAR in range(2020,2025):\n",
    "    \n",
    "    for MONTH in range(1,12):\n",
    "        \n",
    "        days = calendar.monthrange(YEAR, MONTH)[1]\n",
    "        print(days)\n",
    "        for day in range(1, days + 1):\n",
    "            date_str = f\"{YEAR}-{MONTH:02d}-{day:02d}\"\n",
    "            print(f\"\\nüìÖ Processando {date_str}\")\n",
    "            \n",
    "            for device_key, device_info in DEVICES.items():\n",
    "                print(f\"üì• Baixando dados da esta√ß√£o {device_info['nome']} ({device_info['cod']})\")\n",
    "                data = fetch_data_day(device_info[\"cod\"], date_str)\n",
    "                if not data:\n",
    "                    continue\n",
    "                \n",
    "                results = []\n",
    "                for pollutant, values in data.items():\n",
    "                    if not values:\n",
    "                        continue  # ignora None ou lista vazia\n",
    "                \n",
    "                    # Garantir que values √© iter√°vel e adequado\n",
    "                    if isinstance(values, list) and len(values) > 0 and isinstance(values[0], dict):\n",
    "                        temp_df = pd.DataFrame(values)\n",
    "                    else:\n",
    "                        print(f\"‚ö†Ô∏è Pulando poluente {pollutant}, formato inesperado: {type(values)}\")\n",
    "                        continue\n",
    "                    \n",
    "                \n",
    "                    temp_df[\"POLUENTE\"] = pollutant\n",
    "                    temp_df[\"ESTACAO\"] = device_info[\"nome\"]\n",
    "                    temp_df[\"COD\"] = device_info[\"cod\"]\n",
    "                    results.append(temp_df)\n",
    "                \n",
    "                if not results:\n",
    "                    continue\n",
    "                \n",
    "                df_all = pd.concat(results, ignore_index=True)\n",
    "                df_all[\"DATETIME\"] = pd.to_datetime(date_str + \" \" + df_all[\"hour\"])\n",
    "                \n",
    "                # Salvar CSV por esta√ß√£o e poluente\n",
    "                # Exemplo de dicion√°rio para padronizar nomes de poluentes e √≠ndices\n",
    "                pollutant_name_map = {\n",
    "                    \"avg_co\": \"CO\",\n",
    "                    \"avg_no2\": \"NO2\",\n",
    "                    \"avg_so2\": \"SO2\",\n",
    "                    \"avg_pm100\": \"PTS\",\n",
    "                    \"avg_pm10\": \"MP10\",\n",
    "                    \"avg_pm25\": \"MP25\",\n",
    "                    \"avg_o3\": \"O3\",\n",
    "                    \"avg_uv\": \"UV\",\n",
    "                    \"avg_co_iqar\": \"CO_IQAR\",\n",
    "                    \"avg_no2_iqar\": \"NO2_IQAR\",\n",
    "                    \"avg_o3_iqar\": \"O3_IQAR\",\n",
    "                    \"avg_uv_iqar\": \"UV_IQAR\",\n",
    "                    \"avg_pm25_iqar\": \"MP25_IQAR\",\n",
    "                    \"avg_pm10_iqar\": \"MP10_IQAR\",\n",
    "                    \"avg_o3_index\": \"O3_INDEX\",\n",
    "                    \"avg_uv_index\": \"UV_INDEX\",\n",
    "                    \"avg_pm25_index\": \"MP25_INDEX\",\n",
    "                    \"avg_pm10_index\": \"MP10_INDEX\"\n",
    "                }\n",
    "                \n",
    "        \n",
    "        \n",
    "                # Transformar para formato longo\n",
    "                df_long = df_all.melt(\n",
    "                    id_vars=[\"DATETIME\", \"ESTACAO\", \"COD\"],  # colunas que permanecem\n",
    "                    value_vars=pollutant_cols,               # colunas que viram 'POLUENTE'\n",
    "                    var_name=\"POLUENTE\",\n",
    "                    value_name=\"CONC\"\n",
    "                )\n",
    "                \n",
    "                # Substituir nomes pelo padr√£o, se existir no dicion√°rio\n",
    "                df_long[\"POLUENTE\"] = df_long[\"POLUENTE\"].map(lambda x: pollutant_name_map.get(x, x))\n",
    "        \n",
    "        \n",
    "                for (station, pollutant), group in df_long.groupby([\"ESTACAO\", \"POLUENTE\"]):\n",
    "                    filename = f\"MA_{station}_{pollutant}_{date_str}.csv\".replace(\" \", \"_\")\n",
    "                    filepath = os.path.join(OUTPUT_DIR, filename)\n",
    "                    group = group.drop([\"POLUENTE\",\"ESTACAO\"], axis=1)\n",
    "                    group.to_csv(filepath, index=False, encoding=\"utf-8\")\n",
    "                    print(f\"‚úÖ Saved: {filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3858768-1700-4776-ad4c-f649c8a6f599",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
