{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab275d25-ca0a-4da1-a1f7-6b23184845a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os parâmetros para o webscraping\n",
    "import pandas as pd\n",
    "\n",
    "# Dicionários fornecidos\n",
    "dict1 = {\n",
    " 'CH4 - Metano [ppm]': '7',\n",
    " 'HCNM - Hidrocarbonetos Não-Metano [ppm]': '11',\n",
    " 'HCT - Hidrocarbonetos Totais [ppm]': '2143',\n",
    " 'MP10 - Partículas Inaláveis (<10µm) [µg/m³]': '18',\n",
    " 'MP2,5 - Partículas Inaláveis (<2,5µm) [µg/m³]': '20',\n",
    " 'NO - Monóxido de Nitrogênio [µg/m³]': '2128',\n",
    " 'NO2 - Dióxido de Nitrogênio [µg/m³]': '1465',\n",
    " 'NOX - Óxidos de Nitrogênio [µg/m³]': '9',\n",
    " 'O3 - Ozônio [µg/m³]': '2130',\n",
    " 'PTS - Partículas Totais em Suspensão [µg/m³]': '1955',\n",
    " 'SO2 - Dióxido de Enxofre [µg/m³]': '23',\n",
    " 'DV - Direção do Vento [°]': '100001',\n",
    " 'PA - Pressão Atmosférica [hPa]': '100007',\n",
    " 'PP - Precipitação [mm]': '100004',\n",
    " 'RS - Radiação Solar [W/m²]': '100006',\n",
    " 'TA - Temperatura do Ar [°C]': '100002',\n",
    " 'UR - Umidade Relativa [%]': '100005',\n",
    " 'VV - Velocidade do Vento [m/s]': '100000'\n",
    "}\n",
    "\n",
    "dict2 = {\n",
    " 'BENZ - Benzeno [µg/m³]': '134',\n",
    " 'CH4 - Metano [ppm]': '7',\n",
    " 'CO - Monóxido de Carbono [ppm]': '3',\n",
    " 'ETBENZ - Etil Benzeno [µg/m³]': '263',\n",
    " 'H2S - Sulfeto de Hidrogênio [µg/m³]': '1305',\n",
    " 'HCNM - Hidrocarbonetos Não-Metano [ppm]': '11',\n",
    " 'HCT - Hidrocarbonetos Totais [ppm]': '2143',\n",
    " 'MP10 - Partículas Inaláveis (<10µm) [µg/m³]': '18',\n",
    " 'MP2,5 - Partículas Inaláveis (<2,5µm) [µg/m³]': '20',\n",
    " 'MPX - M,P-Xileno [µg/m³]': '2168',\n",
    " 'NO - Monóxido de Nitrogênio [µg/m³]': '2128',\n",
    " 'NO2 - Dióxido de Nitrogênio [µg/m³]': '1465',\n",
    " 'NOX - Óxidos de Nitrogênio [µg/m³]': '9',\n",
    " 'O3 - Ozônio [µg/m³]': '2130',\n",
    " 'OX - O-Xileno [µg/m³]': '413',\n",
    " 'PTS - Partículas Totais em Suspensão [µg/m³]': '1955',\n",
    " 'SO2 - Dióxido de Enxofre [µg/m³]': '23',\n",
    " 'TOL - Tolueno [µg/m³]': '482',\n",
    " 'XIL - Xileno [µg/m³]': '504',\n",
    " 'DV - Direção do Vento [°]': '100001',\n",
    " 'DVDP - Desvio Padrão Dir. Vento [°]': '20051',\n",
    " 'PA - Pressão Atmosférica [hPa]': '100007',\n",
    " 'PP - Precipitação [mm]': '100004',\n",
    " 'RS - Radiação Solar [W/m²]': '100006',\n",
    " 'TA - Temperatura do Ar [°C]': '100002',\n",
    " 'UR - Umidade Relativa [%]': '100005',\n",
    " 'VV - Velocidade do Vento [m/s]': '100000'\n",
    "}\n",
    "\n",
    "# Merge: dict2 sobrescreve dict1 se houver conflito, mas IDs são iguais\n",
    "merged = {**dict1, **dict2}\n",
    "\n",
    "# Criar DataFrame\n",
    "df_parametros = pd.DataFrame(merged.items(), columns=[\"parameter_name\", \"parameter_id\"])\n",
    "\n",
    "# Definindo as estações e seus códigos\n",
    "stations_dict = {\n",
    "    # Região da Costa Verde\n",
    "    67: \"Mt - Ibicuí\",\n",
    "    64: \"Mt - Itacuruçá\",\n",
    "    68: \"Mt - Praia Do Saco\",\n",
    "    85: \"Mt - Sahy\",\n",
    "    750: \"Mt - Terminal da Ilha Guaíba\",\n",
    "\n",
    "    # Região do Médio Paraíba\n",
    "    73: \"BM - Boa Sorte\",\n",
    "    75: \"BM - Bocaininha\",\n",
    "    76: \"BM - Roberto Silveira\",\n",
    "    74: \"BM - Sesi\",\n",
    "    77: \"BM - Vista Alegre\",\n",
    "    292: \"E. Móvel - Resende\",\n",
    "    82: \"Itt - Campo Alegre\",\n",
    "    83: \"Itt - Meteorológica Itatiaia\",\n",
    "    78: \"PR - Porto Real\",\n",
    "    79: \"Qt - Bom Retiro\",\n",
    "    80: \"Rs - Casa da Lua\",\n",
    "    81: \"Rs - Cidade Alegria\",\n",
    "    69: \"VR - Belmonte\",\n",
    "    72: \"VR - Meteorológica Ilha das Águas Cruas\",\n",
    "    637: \"VR - Nossa Sra. das Graças (Van)\",\n",
    "    70: \"VR - Retiro\",\n",
    "    71: \"VR - Santa Cecília\",\n",
    "\n",
    "    # Região Metropolitana\n",
    "    18: \"BR - São Bernardo\",\n",
    "    733: \"DC - Bacia de Resfriamento\",\n",
    "    30: \"DC - Campos Elíseos\",\n",
    "    735: \"DC - Campos Elíseos (Antiga)\",\n",
    "    31: \"DC - Jardim Primavera\",\n",
    "    35: \"DC - Meteorológica Jardim Piratininga\",\n",
    "    737: \"DC - Pier das Chatas\",\n",
    "    34: \"DC - Pilar\",\n",
    "    32: \"DC - São Bento\",\n",
    "    33: \"DC - Vila São Luiz\",\n",
    "    730: \"E. M. Francisco C. de Alvarenga\",\n",
    "    300: \"E. Móvel  - Velha - Petrópolis\",\n",
    "    298: \"E. Móvel - Belford Roxo\",\n",
    "    297: \"E. Móvel - Engenheiro Pedreira\",\n",
    "    296: \"E. Móvel - Itaguaí EMBRAPA\",\n",
    "    295: \"E. Móvel - Jardim Meriti - Vilar dos Teles - RJ OF\",\n",
    "    282: \"E. Móvel - Lagoa - RJ.\",\n",
    "    281: \"E. Móvel - Linha Amarela LAMSA - RJ\",\n",
    "    291: \"E. Móvel - Velha-Cidade Meninos\",\n",
    "    609: \"Itaborai - Ciep 130 - Meteorologia\",\n",
    "    610: \"Itaborai - Vor Infraero  - Meteorologia\",\n",
    "    608: \"Itb - Alto do Jacú\",\n",
    "    41: \"Itb - Apa Guapimirim\",\n",
    "    40: \"Itb - Areal\",\n",
    "    42: \"Itb - Fazenda Macacu\",\n",
    "    38: \"Itb - Porto das Caixas\",\n",
    "    39: \"Itb - Sambaetiba\",\n",
    "    804: \"Itg - Brisamar\",\n",
    "    63: \"Itg - Coroa Grande\",\n",
    "    747: \"Itg - Estação Gaia\",\n",
    "    66: \"Itg - Ilha Da Madeira\",\n",
    "    65: \"Itg - Meteorológica Ilha Da Madeira\",\n",
    "    60: \"Itg - Monte Serrat\",\n",
    "    55: \"Jp - Engenheiro Pedreira\",\n",
    "    252: \"Monitor - CO  Plaza Shopping\",\n",
    "    57: \"NI - Jardim Guandu\",\n",
    "    28: \"NI - Meteorológica Cerâmica\",\n",
    "    19: \"NI - Monteiro Lobato\",\n",
    "    229: \"Nit - Caio Martins\",\n",
    "    748: \"Nit - Charitas\",\n",
    "    749: \"Nit - Itaipu\",\n",
    "    789: \"Pet - Retiro\",\n",
    "    788: \"Qmd - Meteorológica Jardim Riachão\",\n",
    "    611: \"Radar Vor Da Infraero - Cetrel-Automatica\",\n",
    "    61: \"RJ - Adalgisa Nery\",\n",
    "    742: \"RJ - Aeroporto de Campo dos Afonsos\",\n",
    "    744: \"RJ - Aeroporto do Galeão\",\n",
    "    20: \"RJ - Campo dos Afonsos\",\n",
    "    22: \"RJ - Centro\",\n",
    "    23: \"RJ - Engenhão\",\n",
    "    228: \"RJ - Gamboa\",\n",
    "    24: \"RJ - Gericinó\",\n",
    "    36: \"RJ - Ilha de Paquetá\",\n",
    "    37: \"RJ - Ilha do Governador\",\n",
    "    227: \"RJ - Jacarepaguá\",\n",
    "    226: \"RJ - Lab. INEA\",\n",
    "    25: \"RJ - Lagoa\",\n",
    "    12: \"RJ - Largo do Bodegão\",\n",
    "    225: \"RJ - Leblon\",\n",
    "    26: \"RJ - Lourenço Jorge\",\n",
    "    29: \"RJ - Manguinhos\",\n",
    "    224: \"RJ - Maracanã\",\n",
    "    62: \"RJ - Meteorológica Santa Cruz\",\n",
    "    59: \"RJ - Meteorológica UTE Santa Cruz\",\n",
    "    223: \"RJ - São Conrado\",\n",
    "    21: \"RJ - Taquara\",\n",
    "    222: \"RJ - Urca\",\n",
    "    221: \"RJ - Van (Parque da Serra da Tiririca)\",\n",
    "    220: \"RJ - Van (Parque do Mendanha)\",\n",
    "    219: \"RJ - Van (Parque Parnaso - Guapimirim)\",\n",
    "    218: \"RJ - Van (Sumaré-SBT)\",\n",
    "    217: \"SC - 27ºBPM (Caminhão)\",\n",
    "    745: \"SC - Base Aérea de Santa Cruz\",\n",
    "    216: \"SC - João XXIII (Caminhao)\",\n",
    "    746: \"SG - GETEC\",\n",
    "    27: \"SG - UERJ\",\n",
    "    215: \"SJM  - Coelho da Rocha\",\n",
    "    56: \"Sp - Meteorológica Jardim Maracanã\",\n",
    "    58: \"Sp - Piranema\",\n",
    "\n",
    "    # Região Norte Fluminense\n",
    "    299: \"E. Móvel - Barra Mansa\",\n",
    "    294: \"E. Móvel - Macaé - Norte Fuminense\",\n",
    "    293: \"E. Móvel - Parmalat Macae-RJ\",\n",
    "    613: \"Estação Meteorológica - Ute Campos\",\n",
    "    743: \"Mc - Aeroporto de Macaé\",\n",
    "    43: \"Mc - Cabiúnas\",\n",
    "    47: \"Mc - Fazenda Airis\",\n",
    "    44: \"Mc - Fazenda Severina\",\n",
    "    142: \"Mc - Imboassica\",\n",
    "    740: \"Mc - Macaé Merchant\",\n",
    "    46: \"Mc - Meteorológica Fazenda Severina\",\n",
    "    45: \"Mc - Pesagro\",\n",
    "    49: \"SJB - Açú 5º Distrito\",\n",
    "    86: \"SJB - Fazenda Saco Dantas\",\n",
    "    48: \"SJB - Mato Escuro 5º Distrito\",\n",
    "\n",
    "    # Região Serrana\n",
    "    54: \"Cg - Euclidelândia\",\n",
    "    51: \"Cg - Macuco\",\n",
    "    53: \"Cg - Meteorológica Euclidelândia 1\",\n",
    "    52: \"Cg - Meteorológica Euclidelândia 2\",\n",
    "    50: \"Cg - Val Palmas\"\n",
    "}\n",
    "# Criar DataFrame\n",
    "df_stations = pd.DataFrame(list(stations_dict.items()), columns=[\"station_id\", \"station_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "152ddb12-ab67-4cb2-9c23-18b2eef7516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "def webscraper_RJ(station_id,parameter_id,start_date,end_date,year):\n",
    "    url = \"https://ei.weblakes.com/INEAPublico/AMSTabularData/GridData\"\n",
    "    params = {\n",
    "        \"aStationType\": \"1\",\n",
    "        \"aSites\": station_id,                # station ID\n",
    "        \"aParameters\": parameter_id,       # pollutant ID\n",
    "        \"aStartDate\": start_date,\n",
    "        \"aEndDate\": end_date,\n",
    "        \"aShowRawData\": \"True\",\n",
    "        \"anAvgPeriod\": \"1\",\n",
    "        \"aDataSouce\": \"1\",\n",
    "        \"aAvgType\": \"1\",\n",
    "        \"gridId\": \"TabularTimeGrid\",\n",
    "        \"Context_Bootstrap_Flag\": \"true\",\n",
    "        \"_search\": \"false\",\n",
    "        \"nd\": \"1755542020437\",\n",
    "        \"rows\": \"20\",\n",
    "        \"page\": \"1\",\n",
    "        \"sidx\": \"Time\",\n",
    "        \"sord\": \"asc\",\n",
    "        \"ssSearchField\": \"__ANY_COLUMN\",\n",
    "        \"ssSearchOper\": \"cn\",\n",
    "        \"ssSearchString\": \"\",\n",
    "        \"_\": \"1755541897561\"\n",
    "    }\n",
    "    \n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "    resp = requests.get(url, params=params, headers=headers)\n",
    "    data = resp.json()\n",
    "    \n",
    "    records = []\n",
    "    for row in data[\"rows\"]:\n",
    "        cells = row[\"cell\"]\n",
    "        # extract datetime from span\n",
    "        soup = BeautifulSoup(cells[2], \"html.parser\")\n",
    "        timestamp = soup.text.strip()\n",
    "        soup = BeautifulSoup(cells[3], \"html.parser\")\n",
    "        value = soup.text.strip()\n",
    "        for ii, val in enumerate(value):\n",
    "            if val=='':\n",
    "                value[ii] = np.nan\n",
    "            else:\n",
    "                if np.size(value)>1:\n",
    "                    value[ii] = np.float64(val)\n",
    "                else:\n",
    "                    value = np.float64(value)\n",
    "            \n",
    "        #value = cells[3]\n",
    "        qaqc = cells[4]\n",
    "        records.append({\"datetime\": timestamp, \"value\": value, \"qaqc\": qaqc})\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    if df.shape[0]>1:\n",
    "        df.to_csv(str(year)+'_'+str(station_id)+'_'+str(parameter_id)+'.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edf3af21-771e-44b9-a1eb-c5640bafa1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "station_id               67\n",
      "station_name    Mt - Ibicuí\n",
      "Name: 0, dtype: object\n",
      "parameter_name    CH4 - Metano [ppm]\n",
      "parameter_id                       7\n",
      "Name: 0, dtype: object\n",
      "10 seconds have passed. Program continuing...\n",
      "parameter_name    HCNM - Hidrocarbonetos Não-Metano [ppm]\n",
      "parameter_id                                           11\n",
      "Name: 1, dtype: object\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m webscraper_RJ(\u001b[38;5;28mstr\u001b[39m(row.station_id),rowParam.parameter_id,\u001b[38;5;28mstr\u001b[39m(year)+\u001b[33m'\u001b[39m\u001b[33m-01-01\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;28mstr\u001b[39m(year+\u001b[32m1\u001b[39m)+\u001b[33m'\u001b[39m\u001b[33m-01-01\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Pause execution for 10 seconds\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m10 seconds have passed. Program continuing...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "years = np.arange(1965,2024)\n",
    "\n",
    "for year in years:\n",
    "    for ii, row in df_stations.iterrows():\n",
    "        print(row)\n",
    "        for jj, rowParam in df_parametros.iterrows():\n",
    "            print(rowParam)\n",
    "            webscraper_RJ(str(row.station_id),rowParam.parameter_id,str(year)+'-01-01',str(year+1)+'-01-01',import time)\n",
    "            # Pause execution for 10 seconds\n",
    "            time.sleep(10)\n",
    "            print(\"10 seconds have passed. Program continuing...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb702c0f-3eea-4650-a208-f2efe43e4bb4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# Extract all options\u001b[39;00m\n\u001b[32m     59\u001b[39m station_parameters = {}\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m option \u001b[38;5;129;01min\u001b[39;00m \u001b[43mstation_select\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind_all\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33moption\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     61\u001b[39m     value = option.get(\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     62\u001b[39m     text = option.text.strip()\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "url = \"https://ei.weblakes.com/INEAPublico/AMSTabularData/GridData\"\n",
    "params = {\n",
    "    \"aStationType\": \"1\",\n",
    "    \"aSites\": \"67\",                # station ID\n",
    "    \"aParameters\": \"1955\",       # pollutant ID\n",
    "    \"aStartDate\": \"2024-08-08\",\n",
    "    \"aEndDate\": \"2024-10-10\",\n",
    "    \"aShowRawData\": \"false\",\n",
    "    \"anAvgPeriod\": \"1\",\n",
    "    \"aDataSouce\": \"1\",\n",
    "    \"aAvgType\": \"1\",\n",
    "    \"gridId\": \"TabularTimeGrid\",\n",
    "    \"Context_Bootstrap_Flag\": \"true\",\n",
    "    \"_search\": \"false\",\n",
    "    \"nd\": \"1755542020437\",\n",
    "    \"rows\": \"20\",\n",
    "    \"page\": \"1\",\n",
    "    \"sidx\": \"Time\",\n",
    "    \"sord\": \"asc\",\n",
    "    \"ssSearchField\": \"__ANY_COLUMN\",\n",
    "    \"ssSearchOper\": \"cn\",\n",
    "    \"ssSearchString\": \"\",\n",
    "    \"_\": \"1755541897561\"\n",
    "}\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "resp = requests.get(url, params=params, headers=headers)\n",
    "data = resp.json()\n",
    "\n",
    "records = []\n",
    "for row in data[\"rows\"]:\n",
    "    cells = row[\"cell\"]\n",
    "    # extract datetime from span\n",
    "    soup = BeautifulSoup(cells[2], \"html.parser\")\n",
    "    timestamp = soup.text.strip()\n",
    "    soup = BeautifulSoup(cells[3], \"html.parser\")\n",
    "    value = soup.text.strip()\n",
    "    for ii, val in enumerate(value):\n",
    "        if val=='':\n",
    "            value[ii] = np.nan\n",
    "        else:\n",
    "            if np.size(value)>1:\n",
    "                value[ii] = np.float64(val)\n",
    "            else:\n",
    "                value = np.float64(value)\n",
    "        \n",
    "    #value = cells[3]\n",
    "    qaqc = cells[4]\n",
    "    records.append({\"datetime\": timestamp, \"value\": value, \"qaqc\": qaqc})\n",
    "\n",
    "# Transforma em um DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Find the <select> with id=\"stationParameters\"\n",
    "station_select = soup.find(\"select\", id=\"stationParameters\")\n",
    "\n",
    "# Extract all options\n",
    "station_parameters = {}\n",
    "for option in station_select.find_all(\"option\"):\n",
    "    value = option.get(\"value\")\n",
    "    text = option.text.strip()\n",
    "    station_parameters[value] = text\n",
    "\n",
    "\n",
    "df_stations_parameters = pd.DataFrame(station_parameters, index=[0])\n",
    "# Append the dictionary as a new row\n",
    "df_stations_parameters.loc[len(df_stations_parameters)] = station_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f82976fc-d8dc-47e3-8a05-3207f66cbb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            datetime value  \\\n",
      "0  <span data-value='2025-08-18T00:00:00'>18-Aug-...         \n",
      "1  <span data-value='2025-08-18T01:00:00'>18-Aug-...         \n",
      "2  <span data-value='2025-08-18T02:00:00'>18-Aug-...         \n",
      "3  <span data-value='2025-08-18T03:00:00'>18-Aug-...         \n",
      "4  <span data-value='2025-08-18T04:00:00'>18-Aug-...         \n",
      "\n",
      "                           qaqc  \n",
      "0  Disabilitada Temporariamente  \n",
      "1  Disabilitada Temporariamente  \n",
      "2  Disabilitada Temporariamente  \n",
      "3  Disabilitada Temporariamente  \n",
      "4  Disabilitada Temporariamente  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://ei.weblakes.com/INEAPublico/AMSTabularData/GridData\"\n",
    "\n",
    "params = {\n",
    "    \"aStationType\": \"1\",\n",
    "    \"aSites\": \"67\",                # ID da estação\n",
    "    \"aParameters\": \"100001\",       # ID do poluente\n",
    "    \"aStartDate\": \"2025-08-18\",\n",
    "    \"aEndDate\": \"2025-08-18\",\n",
    "    \"aShowRawData\": \"false\",\n",
    "    \"anAvgPeriod\": \"1\",\n",
    "    \"aDataSouce\": \"1\",\n",
    "    \"aAvgType\": \"1\",\n",
    "    \"gridId\": \"TabularTimeGrid\",\n",
    "    \"Context_Bootstrap_Flag\": \"true\",\n",
    "    \"_search\": \"false\",\n",
    "    \"nd\": \"1755559737239\",\n",
    "    \"rows\": \"9999\",   # aumenta pra pegar tudo\n",
    "    \"page\": \"1\",\n",
    "    \"sidx\": \"Time\",\n",
    "    \"sord\": \"asc\",\n",
    "    \"ssSearchField\": \"__ANY_COLUMN\",\n",
    "    \"ssSearchOper\": \"cn\",\n",
    "    \"ssSearchString\": \"\"\n",
    "}\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "resp = requests.get(url, params=params, headers=headers)\n",
    "resp.raise_for_status()\n",
    "\n",
    "data = resp.json()   # Agora funciona sem erro de JSON\n",
    "records = []\n",
    "for row in data[\"rows\"]:\n",
    "    cells = row[\"cell\"]\n",
    "    records.append({\n",
    "        \"datetime\": cells[2],  # já vem em texto\n",
    "        \"value\": cells[3],\n",
    "        \"qaqc\": cells[4]\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6fd82ad8-a5a2-40fb-b6c0-b8c6bd8ff67b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2929934-5463-4894-a4f0-0b2abcb344f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
